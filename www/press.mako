<%inherit file="_index.mako"/>

<div id="article">
    <div class="container">
        <div class="press row">
            <div class="span2">
                <p><img src="/static/wtju.png"></p>
            </div>
            <div class="span6">
                <h4>COS on WTJU</h4>
                <p>January 17th, 2014 | Andrew Sallans and Josh Carp of the Center for Open Science were interviewed on WTJU's Soundboard.</p>
                <p><a href="/static/WTJUinterview.mp3">Listen</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/cos_logo.png"></p>
            </div>
            <div class="span6">
                <h4>The John Templeton Foundation awards $2.1M joining the Laura and John Arnold Foundation and Alfred P. Sloan Foundation in $10M year for COS</h4>
                <p>December 23rd, 2013 | Initiated by a grant from the Laura and John Arnold Foundation in early 2013, the Center for Open Science (COS; http://cos.io/) received additional support from an anonymous donor in March to accelerate development of the Open Science Framework (http://osf.io/). The OSF is a free web application that supports the scientific workflow, making it easy for researchers to document, archive, and share their research materials and data. In June, the Alfred P. Sloan Foundation gave an award to connect the OSF with tools created by other open source and open science service providers to support data management planning, pre-registration of research designs, data archiving, data analysis, and journal management. This month, COS will make the first major feature release from the Alfred P. Sloan Foundation support.</p>
                <p><a href="http://cos.io/pr/2013-12-23/">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/Science.gif"></p>
            </div>
            <div class="span6">
                <h4>Second Look at Psychology Experiments Offers Reassurance</h4>
                <p>November 27th, 2013 | Big research collaborations have become common—think Human Genome Project, Mars rovers, the new BRAIN Initiative—but they are almost unknown in psychology. Most psychological experiments are carried out by a single lab group, often just a few researchers. But several collaborations that span dozens of psychology laboratories around the world have recently formed. Their goal is nothing short of testing the reproducibility of psychological science.</p>
                <p><a href="http://news.sciencemag.org/social-sciences/2013/11/second-look-psychology-experiments-offers-reassurance">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/ng.png"></p>
            </div>
            <div class="span6">
                <h4>Welcome To The Era of Big Replication</h4>
                <p>November 26th, 2013 | "It is very telling that everyone I spoke to praised the initiative, including the authors whose work did not replicate. There was none of the acrimony that has stained past debates. When something is done this well, it’s pretty churlish to not accept the results.</p>

                <p>This is a harbinger of things to come.” </p>
                <p><a href="http://phenomena.nationalgeographic.com/2013/11/26/welcome-to-the-era-of-big-replication/">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/nature.png"></p>
            </div>
            <div class="span6">
                <h4>Psychologists strike a blow for reproducibility</h4>
                <p>November 26th, 2013 | “This is a really important initiative for psychology,” says Danny Oppenheimer, a psychologist at the University of California, Los Angeles, whose work was under scrutiny but who did not take part in the collaboration. “It means that the replicability problem, while by no means trivial, may not be as widespread as some critics of the field have suggested.” </p>
                <p><a href="http://www.nature.com/news/psychologists-strike-a-blow-for-reproducibility-1.14232">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/nature.png"></p>
            </div>
            <div class="span6">
                <h4>Receptive to replication</h4>
                <p>November 8th, 2013 | The Reproducibility Initiative (Nat. Biotechnol. 30, 806, 2012) represents another way of replicating research. A collaboration between the Science Exchange and PLOS ONE, the initiative offers to broker independent validation of a researcher's work in return for a fee, with subsequent publication in the journal. In October, the Laura and John Arnold Foundation provided $1.3 million to the initiative to authenticate 50 high-profile cancer papers from the past two years.</p>
                <p><a href="http://www.nature.com/nbt/journal/v31/n11/full/nbt.2748.html">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/newyorker.png"></p>
            </div>
            <div class="span6">
                <h4>Science and Its Skeptics</h4>
                <p>November 7th, 2013 | The wholesale shift in the culture of how scientists think about their craft is at least as significant a meta-story as the replicability crisis itself. But the prophets of doom never let their readers in on this happy secret.</p>
                <p><a href="http://www.newyorker.com/online/blogs/elements/2013/11/science-and-its-skeptics.html">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/observer_flag.jpg"></p>
            </div>
            <div class="span6">
                <h4>What’s New at Psychological Science: An Interview with Editor in Chief Eric Eich</h4>
                <p>November 1st, 2013 | Initiatives launching at Psychological Science in 2014 have the potential for far-reaching effects on authors, readers, and science as a whole. The Academic Observer sat down with Editor in Chief Eric Eich to talk about his experience with the journal so far and the exciting new changes ahead.</p>
                <p><a href="http://www.psychologicalscience.org/index.php/publications/observer/2013/november-2013/whats-new-at-psychological-science.html">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/aps.jpg"></p>
            </div>
            <div class="span6">
                <h4>APS Replication Initiative Under Way</h4>
                <p>November 1st, 2013 | Earlier this year, Perspectives on Psychological Science announced the first project of the new Registered Replication Report (RRR) initiative, which aims to support high-quality, multi-center replications of important psychological findings. The response was tremendous: 30 labs from all over the world are currently participating in our first RRR project.</p>
                <p><a href="http://www.psychologicalscience.org/index.php/publications/observer/2013/november-2013/aps-replication-initiative-underway.html">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/sciam_logo.png"></p>
            </div>
            <div class="span6">
                <h4>You can’t read just one: Reproducibility and multiple sources</h4>
                <p>October 29th, 2013 | We teach students in introductory science classes that reproducibility is one of the hallmarks of science. As they learn more about their disciplines, they need to be aware of the practical challenges involved in reproducing the work of others, and the importance of finding multiple sources about a topic needs to be emphasized.</p>
                <p><a href="http://blogs.scientificamerican.com/information-culture/2013/10/29/you-cant-read-just-one-reproducibility-and-multiple-sources/">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/reason_logo.png"></p>
            </div>
            <div class="span6">
                <h4>Are Most Scientific Results Bunk?</h4>
                <p>October 28th, 2013 | Nosek's Open Science Framework project seems like a promising way to nudge researchers toward greater transparency and less data dredging. Through the system researchers can obtain "badges" for project pre-registration, open data, and open materials. Presumably these badges will help persuade journal editors to be more likely to publish such studies and thus encourage better research practices. </p>
                <p><a href="http://reason.com/blog/2013/10/28/are-most-scientific-results-bunk">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/economist.png"></p>
            </div>
            <div class="span6">
                <h4>Trouble at the lab</h4>
                <p>October 19th, 2013 | The idea that the same experiments always get the same results, no matter who performs them, is one of the cornerstones of science’s claim to objective truth. If a systematic campaign of replication does not lead to the same results, then either the original research is flawed (as the replicators claim) or the replications are (as many of the original researchers on priming contend). Either way, something is awry.</p>
                <p><a href="http://www.economist.com/news/briefing/21588057-scientists-think-science-self-correcting-alarming-degree-it-not-trouble">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/SE_Logo.png"></p>
            </div>
            <div class="span6">
                <h4>Reproducibility Initiative Receives $1.3M Grant to Validate 50 Landmark Cancer Studies</h4>
                <p>October 16th, 2013 | The Center for Open Science announced​ ​today that it would designate $1.3M of funding from the Laura and John Arnold Foundation towards the Reproducibility​ ​Initiative​ to independently validate 50
                    landmark cancer biology studies. The 50​ ​chosen studies are among the highest impact studies in the field over the period of 2010 to 2012, and systematic​ ​validation could be crucial to developing future cancer drugs.</p>
                <p><a href="/pr/2013-10-16">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/Science.gif"></p>
            </div>
            <div class="span6">
                <h4>Your Data, Warts and All</h4>
                <p>October 4th, 2013 | The imperative for thorough, transparent, and accurate reporting is often in conflict with the need young scientists have to add items to their CVs. Fortunately there are ways—some straightforward and safe; others risky or requiring more effort—to manage this conflict, staying close to data-disclosure ideals while also getting on with your career. "You need to understand how the present culture of science works in order to know how to be pragmatic about pursuing your ideals," Nosek says.</p>
                <p><a href="http://sciencecareers.sciencemag.org/career_magazine/previous_issues/articles/2013_10_04/caredit.a1300211">Read more</a></p>
            </div>
        </div> <!-- row -->
    <div class="press row">
            <div class="span2">
                <p><img src="/static/hycos.png"></p>
            </div>
            <div class="span6">
                <h4>The Center for Open Science Hosts HackYourPhD</h4>
                <p>August 27th, 2013 | Célya Gruson-Daniel (<a href="https://twitter.com/celyagd">@celyagd</a>) will open with a short presentation of HackYourPhD (<a href="https://twitter.com/hackyourphd">@HackYourPhD</a>), which she co-founded.  Célya is based in Paris and has been touring the United States this summer producing a web documentary focused on the open science community. She will introduce individuals she has met during the HackYourPhD open science tour, her discoveries, and the questions that were raised concerning the future of open science. Célya will be concluding her documentary in Charlottesville at the Center for Open Science.</p>
                <p><a href="/pr/2013-08-27/">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/newyorker.png"></p>
            </div>
            <div class="span6">
                <h4>The Crisis in Social Psychology That Isn&#8217;t</h4>
                <p>May 1st, 2013 | Things aren&#8217;t quite as bad as they seem, though. Although Nature&#8217; report was headlined &#8220;Disputed results a fresh blow for social psychology,&#8221; it scarcely noted that there have been some replications of experiments modelled on Dijksterhuis&#8217;s phenomenon. His finding could still turn out to be right, if weaker than first thought. More broadly, social priming is just one thread in the very rich fabric of social psychology. The field will survive, even if social priming turns out to have been overrated or an unfortunate detour.</p>
                <p><a href="http://www.newyorker.com/online/blogs/elements/2013/05/the-crisis-in-social-psychology-that-isnt.html" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/ng.png"></p>
            </div>
            <div class="span6">
                <h4>New Center Aims to Make Science More Open and Reliable</h4>
                <p>March 5th, 2013 | The field of psychology is going through a period of introspective turmoil. On the one hand, it has never been more popular. Its results lead to attention-grabbing headlines, and fill books that sit happily on bestseller lists. Conversely, some of its own practitioners are starting to ask themselves a difficult question: What proportion of the field&#8217;s findings are genuine and reliable insights into the human mind, and what proportion are red herrings produced by questionable research practices and, in rare cases, outright fraud?</p>
                <p><a href="http://phenomena.nationalgeographic.com/2013/03/05/new-center-aims-to-make-science-more-open-and-reliable/" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/Science.gif"></p>
            </div>
            <div class="span6">
                <h4>Psychologists Launch a Bare-All Research Initiative</h4>
                <p>March 5th, 2013 | A group of psychologists are launching a project this week that they hope will make studies in their field radically more transparent and prompt other fields to open up as well. With a pledge of $5.25 million from private supporters, they have set up an outfit called the Center for Open Science. It is collaborating with an established journal, <em>Perspectives on Psychological Science</em>, to solicit work from authors who are willing to work completely in the open and have their studies replicated. Authors will be asked to first publish an experimental design and then, after a public vetting, collect data. Findings come in a separate publication. Authors would get credit for all steps in this process: experimental designs, peer review, delivering results, and replicating them.</p>
                <p><a href="http://news.sciencemag.org/2013/03/psychologists-launch-bare-all-research-initiative/" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
                <div class="press row">
            <div class="span2">
                <p><img src="/static/cos_logo.png"></p>
            </div>
            <div class="span6">
                <h4>Center for Open Science to provide revolutionary approach to scientific communication</h4>
                <p>March 5th, 2013 | Scientific research aims to create knowledge about how the world works. Knowledge accumulates when scientists conduct studies and share their findings with others. Sharing allows other scientists to identify flaws or ot extend the findings to get more knowledge. Given its importance, it is surprising that a large portion of scientific research is never shared at all. The Center for Open Science, which opens today in Charlottesville, Virginia, aims to improve how science is conducted and communicated.  <a href="/static/pr/cos_pr_20130305.docx"><img src="/static/page_white_word.png"/></a> <a href="/static/pr/cos_pr_20130305.pdf"><img src="/static/page_white_acrobat.png"/></a></p>
                <p><a href="/pr/2013-03-05/">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/chronicle.jpg"></p>
            </div>
            <div class="span6">
                <h4>New Center Hopes to Clean Up Sloppy Science and Bogus Research</h4>
                <p>March 5th, 2013 | Something is wrong with science, or at least with how science is
often done. Flashy research in prestigious journals later proves to
be bogus. Researchers have built careers on findings that are
dubious or even turn out to be fraudulent. Much of the conversation
about that trend has focused on flaws in social psychology, but the
problem is not confined to a single field.</p>
                <p><a href="http://chronicle.com/article/New-Center-Hopes-to-Clean-Up/137683/">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/pacstand.png"></p>
            </div>
            <div class="span6">
                <h4>Replicate This</h4>
                <p>February 26th, 2013 | [M]any of the classic studies that led us to our current understanding of priming have never been replicated. In fact, the few attempts to reproduce the results that we have taken at face value for so long have failed. In late 2012, that led Daniel Kahneman, noted Princeton University psychologist and author of the best-selling book Thinking Fast and Slow, to write an open e-mail to the entire priming-research community. He wrote, &#8220;Your field is now the poster child for doubts about the integrity of psychological research.&#8221; Kahneman&#8217;s solution? A new research protocol whereby cooperating labs attempt to check and replicate each other&#8217;s studies.</p>
                <p><a href="http://www.psmag.com/magazines/march-april-2013/reproducibility-project-science-53141/">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/nyt.png"></p>
            </div>
            <div class="span6">
                <h4>Primed for Controversy</h4>
                <p>February 24th, 2013 | In 2005, the writer Malcolm Gladwell introduced readers to the phenomenon of &#8220;thinking without thinking&#8221; - the mental work we all do automatically - in his blockbuster book &#8220;Blink.&#8221;</p>

<p>Typical of the genre is a reliance on the &#8220;goal-priming effect,&#8221; in which study subjects automatically and unintentionally alter their thoughts or behavior when prompted by various kinds of information.</p>

<p>But now, goal-priming experiments are coming under scrutiny - and in the process, revealing a problem at the heart of psychological research itself.</p>
                <p><a href="http://www.nytimes.com/2013/02/24/opinion/sunday/psychology-research-control.html?_r=0" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/huffpo.png"></p>
            </div>
            <div class="span6">
                <h4>The Crisis in Squishy Science: Trouble for Scientists and for Journalists</h4>
                <p>February 20th, 2013 | I should be embarrassed. I&#8217;m a social psychologist and my field seems to be in a heap of trouble these days. All of the squishy sciences are getting battered.</p>

<p>&#8220;Squishy&#8221; isn&#8217;t an insult. To me, it is more of a term of endearment. I use it to refer to all of the sciences that try in some way to study humans.</p>
                <p><a href="http://www.huffingtonpost.com/bella-depaulo/the-crisis-in-squishy-sci_b_2697848.html" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/nbc.png"></p>
            </div>
            <div class="span6">
                <h4>Scandals force psychologists to do some soul-searching</h4>
                <p>February 20th, 2013 | In the wake of several scandals in psychology research, scientists are asking themselves just how much of their research is valid.</p>

<p>In the past 10 years, dozens of studies in the psychology field have been retracted, and several high-profile studies have not stood up to scrutiny when outside researchers tried to replicate the research.</p>
                <p><a href="http://www.nbcnews.com/science/scandals-force-psychologists-do-some-soul-searching-1C8453878" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/apa.png"></p>
            </div>
            <div class="span6">
                <h4>Interesting results: Can they be replicated?</h4>
                <p>February 2013 | In psychology, as in other sciences, replication is the gold standard. In theory, new knowledge doesn&#8217;t make it into the canon until the studies that produced it have been verified, independently, by more than one researcher. But in practice, critics say the field rarely lives up to that ideal - and the result is a psychological literature rife with findings that may or may not be true, yet are generally accepted as valid.</p>
                <p><a href="http://www.apa.org/monitor/2013/02/results.aspx" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/newyorker.png"></p>
            </div>
            <div class="span6">
                <h4>Cleaning Up Science</h4>
                <p>December 24th, 2012 | A lot of scientists have been busted recently for making up data and fudging statistics. One case involves a Harvard professor who I once knew and worked with; another a Dutch social psychologist who made up results by the bushel. Medicine, too, has seen a rash of scientific foul play; perhaps most notably, the dubious idea that vaccines could cause autism appears to have been a hoax perpetrated by a scientific cheat. A blog called RetractionWatch publishes depressing notices, almost daily.</p>
                <p><a href="http://www.newyorker.com/online/blogs/newsdesk/2012/12/cleaning-up-science.html" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/atlantic.png"></p>
            </div>
            <div class="span6">
                <h4>The Myth of Self-Correcting Science</h4>
                <p>December 20th, 2012 | Over the last two years, the field of psychology has endured a wave of scandal bookended by fraud cases involving Harvard primatologist Marc Hauser and Dutch social psychologist Diederik Stapel. Even researchers desensitized by scandal-fatigue did a double take when the final report on Stapel&#8217;s case came out last month. The extent of his creative misinterpretation of the facts make the Hauser case look like child&#8217;s play. Stapel not only manipulated and fabricated data, he invented entire schools where said data was allegedly collected.</p>
                <p><a href="http://www.theatlantic.com/health/archive/2012/12/the-myth-of-self-correcting-science/266228/" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/Science.gif"></p>
            </div>
            <div class="span6">
                <h4>Final Report on Stapel Also Blames Field As a Whole</h4>
                <p>December 7th, 2012 | A joint report on disgraced social psychologist Diederik Stapel was issued on 28 November by three committees, one for each of the universities where he worked. [...] In a video statement, he said he was deeply sorry and announced he had written an autobiography to explain how his fraud happened. But the key message in the joint report said that the fraud is not just about Stapel but colleagues, co-authors, reviewers, and editors at even the most prestigious journals.</p>
                <p><a href="http://www.sciencemag.org/content/338/6112/1270.summary" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/os_summit.png"></p>
            </div>
            <div class="span6">
                <h4>Video: Solving the Crisis of Reproducing Science Research</h4>
                <p>October 19th, 2012 | Elizabeth Bartmess, Michael Cohn, and Jeff Spies take part in presenting at the Open Science Summit. Bartmess/Cohn starts at 55:00 and Spies starts at 1:15:00.</p>
                <p><a href="http://fora.tv/2012/10/19/Crisis_of_Reproducing_Science_Research__How_to_Solve_It" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/chronicle.jpg"></p>
            </div>
            <div class="span6">
                <h4>Daniel Kahneman Sees &#8216;Train-Wreck Looming&#8217; for Social Psychology</h4>
                <p>October 5th, 2012 | Daniel Kahneman sent an e-mail last week to a dozen social psychologists, spelling out what he sees as a way to restore the credibility of priming research. The research, which has found that small cues can cause strong subconscious effects, have come under fire after attempts to replicate some high-profile studies failed. It hasn&#8217;t helped that some prominent social psychologists have committed flat-out fraud.</p>
                <p><a href="http://chronicle.com/blogs/percolator/daniel-kahneman-sees-train-wreck-looming-for-social-psychology/31338" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
                <div class="press row">
            <div class="span2">
                <p><img src="/static/econlib.jpg"></p>
            </div>
            <div class="span6">
                <h4>Nosek on Truth, Science, and Academic Incentives</h4>
                <p>September 10th, 2012 | Brian Nosek of the University of Virginia talks with EconTalk host Russ Roberts about how incentives in academic life create a tension between truth-seeking and professional advancement. Nosek argues that these incentives create a subconscious bias toward making research decisions in favor of novel results that may not be true, particularly in empirical and experimental work in the social sciences. In the second half of the conversation, Nosek details some practical innovations occurring in the field of psychology.</p>
                <p><a href="http://www.econtalk.org/archives/2012/09/nosek_on_truth.html" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/Science.gif"></p>
            </div>
            <div class="span6">
                <h4>Service Offers to Reproduce Results for a Fee</h4>
                <p>August 31st, 2012 | A breast cancer biologist is hoping to persuade researchers to have their work replicated for a fee. They would accept the risk of failure but also have a shot at quick validation. The Reproducibility Initiative, launched earlier this month, invites biomedical scientists to submit critical experiments to an advisory board, which matches those experiments with a research facility equipped to repeat them. The original author-and hopefully everyone else-can learn in a short time whether new research holds up. The journal PLoS ONE has pledged to publish any work that comes out of the Reproducibility Initiative.</p>
                <p><a href="http://www.sciencemag.org/content/337/6098/1031.short" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/npg.png"></p>
            </div>
            <div class="span6">
                <h4>Replication studies: Bad copy</h4>
                <p>May 16th, 2012 | For many psychologists, the clearest sign that their field was in trouble came, ironically, from a study about premonition. Daryl Bem, a social psychologist at Cornell University in Ithaca, New York, showed student volunteers 48 words and then abruptly asked them to write down as many as they could remember. Next came a practice session: students were given a random subset of the test words and were asked to type them out. Bem found that some students were more likely to remember words in the test if they had later practised them. Effect preceded cause.</p>
                <p><a href="http://www.nature.com/news/replication-studies-bad-copy-1.10634" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/chronicle.jpg"></p>
            </div>
            <div class="span6">
                <h4>Is Psychology About to Come Undone?</h4>
                <p>April 17th, 2012 | If you&#8217;re a psychologist, the news has to make you a little nervous-particularly if you&#8217;re a psychologist who published an article in 2008 in any of these three journals: <em>Psychological Science</em>, the <em>Journal of Personality and Social Psychology</em>, or the <em>Journal of Experimental Psychology: Learning, Memory, and Cognition</em>.</p>
                <p><a href="http://chronicle.com/blogs/percolator/is-psychology-about-to-come-undone/29045" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
        <div class="press row">
            <div class="span2">
                <p><img src="/static/Science.gif"></p>
            </div>
            <div class="span6">
                <h4>Psychology&#8217;s Bold Initiative</h4>
                <p>March 30th, 2012 | Some psychology researchers argue that a scientific culture that too heavily favors new and counterintuitive ideas over the confirmation of existing results has led to too many findings that are striking for their novelty and published in respected journals-but are nonetheless false.</p>
                <p><a href="http://www.sciencemag.org/content/335/6076/1558" target="_blank">Read more</a></p>
            </div>
        </div> <!-- row -->
    </div> <!-- container -->
</div>

<ul class="breadcrumb">
    <li><a href="/">Home</a> <span class="divider">/</span></li>
    <li class="active">Press</li>
</ul>
